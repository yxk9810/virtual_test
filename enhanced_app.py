import gradio as gr
import subprocess
import os
import time
import threading
import gc
import shutil
from gemini_chat import GeminiChatSession
from system_prompt import prompt

class VirtualChatApp:
    def __init__(self):
        self.chat_session = GeminiChatSession(
            model="gemini-2.0-flash",
            system_instruction=prompt
        )
        self.chat_history = []
        # ä½¿ç”¨æœ¬åœ°è§†é¢‘è·¯å¾„
        self.base_video_path = os.path.expanduser("~/Downloads/kling_20250806_Image_to_Video_this_woman_3742_0.mp4")
        
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.base_video_path):
            print(f"è­¦å‘Š: åŸºç¡€è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {self.base_video_path}")
        else:
            print(f"åŸºç¡€è§†é¢‘æ–‡ä»¶å·²æ‰¾åˆ°: {self.base_video_path}")
        
        # åˆ›å»ºåˆå§‹æ¬¢è¿è§†é¢‘
        self.initial_video = self.create_initial_video()
        
    def create_initial_video(self):
        """åˆ›å»ºåˆå§‹æ¬¢è¿è§†é¢‘"""
        try:
            initial_video_path = "welcome_video.mp4"
            if os.path.exists(self.base_video_path):
                shutil.copy2(self.base_video_path, initial_video_path)
                print(f"åˆå§‹æ¬¢è¿è§†é¢‘å·²åˆ›å»º: {initial_video_path}")
                return initial_video_path
            else:
                print("æ— æ³•åˆ›å»ºåˆå§‹è§†é¢‘ï¼ŒåŸºç¡€è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                return None
        except Exception as e:
            print(f"åˆ›å»ºåˆå§‹è§†é¢‘å¤±è´¥: {e}")
            return None
        
    def process_message(self, user_input, history, progress=gr.Progress()):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„å®Œæ•´æµç¨‹"""
        if not user_input.strip():
            return history, "", None, "âš ï¸ Please enter a message."
            
        # æ›´æ–°çŠ¶æ€
        progress(0.1, desc="ğŸ¤– Generating AI response...")
        
        # 1. è°ƒç”¨Geminiç”Ÿæˆå›å¤æ–‡æœ¬
        print(f"ç”¨æˆ·è¾“å…¥: {user_input}")
        ai_response = self.chat_session.send_message(user_input)
        
        if not ai_response:
            ai_response = "Sorry, I couldn't generate a response. Please try again."
        
        print(f"AIå›å¤: {ai_response}")
        
        # å…ˆå°†æ–‡æœ¬å›å¤æ·»åŠ åˆ°å†å²è®°å½•
        new_history = history + [[user_input, ai_response]]
        
        # 2. æµ‹è¯•éŸ³é¢‘ç”Ÿæˆ
        progress(0.3, desc="ğŸµ Testing audio generation...")
        audio_filename = f"audio_{int(time.time())}.wav"
        
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆé™éŸ³ï¼‰
        try:
            import numpy as np
            import torch
            import torchaudio
            
            # åˆ›å»º3ç§’çš„é™éŸ³éŸ³é¢‘
            sample_rate = 22050
            duration = 3.0
            samples = int(sample_rate * duration)
            silent_audio = np.zeros(samples)
            
            # ä¿å­˜ä¸ºWAVæ–‡ä»¶
            torchaudio.save(audio_filename, torch.tensor(silent_audio).unsqueeze(0), sample_rate)
            print(f"æµ‹è¯•éŸ³é¢‘æ–‡ä»¶å·²åˆ›å»º: {audio_filename}")
            
        except Exception as e:
            print(f"åˆ›å»ºæµ‹è¯•éŸ³é¢‘å¤±è´¥: {str(e)}")
            return new_history, "", None, f"âš ï¸ Audio creation failed: {str(e)}"
        
        # 3. æµ‹è¯•è§†é¢‘å¤„ç†
        progress(0.6, desc="ğŸ¬ Generating response video...")
        video_filename = f"video_{int(time.time())}.mp4"
        
        try:
            # ç®€å•çš„è§†é¢‘å¤åˆ¶ä½œä¸ºæµ‹è¯•
            shutil.copy2(self.base_video_path, video_filename)
            print(f"å“åº”è§†é¢‘æ–‡ä»¶å·²åˆ›å»º: {video_filename}")
            
        except Exception as e:
            print(f"åˆ›å»ºå“åº”è§†é¢‘å¤±è´¥: {str(e)}")
            self.cleanup_file(audio_filename)
            return new_history, "", None, f"âš ï¸ Video creation failed: {str(e)}"
        
        progress(0.9, desc="ğŸ‰ Finalizing...")
        
        # 4. æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(video_filename):
            print(f"å“åº”è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_filename}")
            # æ¸…ç†éŸ³é¢‘æ–‡ä»¶ï¼ˆä¿ç•™è§†é¢‘æ–‡ä»¶ï¼‰
            self.cleanup_file(audio_filename)
            return new_history, "", video_filename, f"âœ… Successfully generated response video: {video_filename}"
        else:
            print("å“åº”è§†é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")
            self.cleanup_file(audio_filename)
            return new_history, "", None, "âš ï¸ Response video file not found."
    
    def cleanup_file(self, filename):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(filename):
                os.remove(filename)
                print(f"å·²æ¸…ç†æ–‡ä»¶: {filename}")
        except Exception as e:
            print(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {filename}: {str(e)}")
    
    def clear_chat(self):
        """æ¸…ç©ºèŠå¤©å†å²"""
        self.chat_session.clear_history()
        return [], "", self.initial_video, "ğŸ’¬ Chat cleared! Ready for new conversation."

def create_interface():
    app = VirtualChatApp()
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
    }
    .chat-container {
        height: 500px !important;
    }
    .video-container {
        height: 400px !important;
    }
    """
    
    with gr.Blocks(title="ğŸ¤– Virtual Chat AI", theme=gr.themes.Soft(), css=custom_css) as demo:
        # æ ‡é¢˜å’Œæè¿°
        gr.Markdown("""
        # ğŸ¤– Virtual Chat with AI Host
        Chat with an AI virtual host! The AI will respond with both text and personalized video messages.
        """)
        
        with gr.Row():
            # å·¦ä¾§ï¼šèŠå¤©åŒºåŸŸ
            with gr.Column(scale=3):
                # èŠå¤©å†å²æ˜¾ç¤º
                chatbot = gr.Chatbot(
                    label="ğŸ’¬ Chat History",
                    height=500,
                    show_label=True,
                    show_share_button=False,
                    show_copy_button=True,
                    elem_classes=["chat-container"],
                    type="messages"
                )
                
                # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
                with gr.Row():
                    msg_input = gr.Textbox(
                        placeholder="Type your message here and press Enter...",
                        label="Your Message",
                        lines=2,
                        scale=4,
                        max_lines=5
                    )
                    send_btn = gr.Button("Send ğŸ“¤", variant="primary", scale=1, size="lg")
                
                # æ§åˆ¶æŒ‰é’®
                with gr.Row():
                    clear_btn = gr.Button("Clear Chat ğŸ—‘ï¸", variant="secondary", size="sm")
                    
            # å³ä¾§ï¼šè§†é¢‘å’ŒçŠ¶æ€åŒºåŸŸ
            with gr.Column(scale=2):
                # è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
                video_output = gr.Video(
                    label="ğŸ¬ AI Response Video",
                    height=400,
                    autoplay=True,
                    show_share_button=False,
                    elem_classes=["video-container"],
                    value=app.initial_video  # è®¾ç½®åˆå§‹è§†é¢‘
                )
                
                # è§†é¢‘æ§åˆ¶æŒ‰é’®
                with gr.Row():
                    play_btn = gr.Button("â–¶ï¸ Play Video", variant="primary", size="sm")
                    pause_btn = gr.Button("â¸ï¸ Pause", variant="secondary", size="sm")
                    stop_btn = gr.Button("â¹ï¸ Stop", variant="secondary", size="sm")
                
                # çŠ¶æ€æ˜¾ç¤º
                status_text = gr.Textbox(
                    label="ğŸ“Š Status",
                    value="ğŸŸ¢ Ready to chat! Type your message and press Send.",
                    interactive=False,
                    lines=3,
                    max_lines=5
                )
                
                # ç³»ç»Ÿä¿¡æ¯
                gr.Markdown("""
                ### â„¹ï¸ System Info
                - **Model**: Gemini 2.0 Flash
                - **TTS**: Test Mode (silent)
                - **Video**: Copy of base video
                - **GPU**: Auto-managed
                """)
        
        # äº‹ä»¶å¤„ç†å‡½æ•°
        def handle_send(user_input, history):
            if not user_input.strip():
                return history, "", None, "âš ï¸ Please enter a message."
            
            # è°ƒç”¨å¤„ç†å‡½æ•°
            new_history, cleared_input, video_file, final_status = app.process_message(user_input, history)
            
            return new_history, cleared_input, video_file, final_status
        
        def handle_clear():
            new_history, cleared_input, cleared_video, status = app.clear_chat()
            return new_history, cleared_input, cleared_video, status
        
        # è§†é¢‘æ§åˆ¶å‡½æ•°
        def play_video():
            return "Playing video..."
        
        def pause_video():
            return "Video paused"
        
        def stop_video():
            return "Video stopped"
        
        # ç»‘å®šäº‹ä»¶
        send_btn.click(
            fn=handle_send,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input, video_output, status_text],
            show_progress=True
        )
        
        msg_input.submit(
            fn=handle_send,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input, video_output, status_text],
            show_progress=True
        )
        
        clear_btn.click(
            fn=handle_clear,
            outputs=[chatbot, msg_input, video_output, status_text]
        )
        
        # è§†é¢‘æ§åˆ¶æŒ‰é’®
        play_btn.click(fn=play_video, outputs=status_text)
        pause_btn.click(fn=pause_video, outputs=status_text)
        stop_btn.click(fn=stop_video, outputs=status_text)
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“‹ Usage Instructions", open=True):
            gr.Markdown("""
            ### Features:
            1. **Welcome Video** - Initial video loads automatically
            2. **Chat with AI** - Full Gemini conversation
            3. **Response Videos** - New videos replace the welcome video
            4. **Video Controls** - Manual play/pause/stop buttons
            5. **Progress Tracking** - Shows processing steps
            
            ### How it Works:
            - The welcome video loads when you open the page
            - When you send a message, a new response video is generated
            - Use the video control buttons to play/pause/stop videos
            - Each conversation generates a unique response video
            
            ### Video Playback:
            - Click "Play Video" to start playback
            - Use "Pause" to pause the video
            - Use "Stop" to stop the video
            - Videos will auto-replace when new responses are generated
            """)
    
    return demo

if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        debug=True,
        show_error=True,
        favicon_path=None
    )
