import gradio as gr
import subprocess
import os
import time
import threading
import gc
import shutil
from gemini_chat import GeminiChatSession
from system_prompt import prompt

class VirtualChatApp:
    def __init__(self):
        self.chat_session = GeminiChatSession(
            model="gemini-2.0-flash",
            system_instruction=prompt
        )
        self.chat_history = []
        # ä½¿ç”¨welcome_video.mp4ä½œä¸ºåŸºç¡€è§†é¢‘
        self.base_video_path = "welcome_video.mp4"
        self.current_video = None  # å½“å‰æ˜¾ç¤ºçš„è§†é¢‘
        
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.base_video_path):
            print(f"è­¦å‘Š: åŸºç¡€è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {self.base_video_path}")
            print("è¯·ç¡®ä¿welcome_video.mp4æ–‡ä»¶å­˜åœ¨äºå½“å‰ç›®å½•")
        else:
            print(f"åŸºç¡€è§†é¢‘æ–‡ä»¶å·²æ‰¾åˆ°: {self.base_video_path}")
        
        # åˆ›å»ºåˆå§‹æ¬¢è¿è§†é¢‘
        self.initial_video = self.create_initial_video()
        self.current_video = self.initial_video
        
    def create_initial_video(self):
        """åˆ›å»ºåˆå§‹æ¬¢è¿è§†é¢‘"""
        try:
            initial_video_path = "welcome_video.mp4"
            if os.path.exists(self.base_video_path):
                # å¦‚æœwelcome_video.mp4å·²ç»å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨
                print(f"ä½¿ç”¨ç°æœ‰çš„æ¬¢è¿è§†é¢‘: {initial_video_path}")
                return initial_video_path
            else:
                print("æ— æ³•åˆ›å»ºåˆå§‹è§†é¢‘ï¼Œwelcome_video.mp4æ–‡ä»¶ä¸å­˜åœ¨")
                return None
        except Exception as e:
            print(f"åˆ›å»ºåˆå§‹è§†é¢‘å¤±è´¥: {e}")
            return None
        
    def process_message(self, user_input, history, progress=gr.Progress()):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„å®Œæ•´æµç¨‹"""
        if not user_input.strip():
            return history, "", self.current_video, "âš ï¸ Please enter a message."
            
        # æ›´æ–°çŠ¶æ€
        progress(0.1, desc="ğŸ¤– Generating AI response...")
        
        # 1. è°ƒç”¨Geminiç”Ÿæˆå›å¤æ–‡æœ¬
        print(f"ç”¨æˆ·è¾“å…¥: {user_input}")
        ai_response = self.chat_session.send_message(user_input)
        
        if not ai_response:
            ai_response = "Sorry, I couldn't generate a response. Please try again."
        
        print(f"AIå›å¤: {ai_response}")
        
        # å…ˆå°†æ–‡æœ¬å›å¤æ·»åŠ åˆ°å†å²è®°å½•ï¼ˆä½¿ç”¨æ­£ç¡®çš„æ ¼å¼ï¼‰
        new_history = history + [{"role": "user", "content": user_input}, {"role": "assistant", "content": ai_response}]
        
        # 2. ç”ŸæˆéŸ³é¢‘
        progress(0.3, desc="ğŸµ Generating audio...")
        audio_filename = f"audio_{int(time.time())}.wav"
        
        try:
            # è°ƒç”¨generate_audio.pyç”ŸæˆéŸ³é¢‘
            cmd = [
                "python", "generate_audio.py", 
                f'"{ai_response}"',  # ä½¿ç”¨AIå›å¤ä½œä¸ºæ–‡æœ¬
                audio_filename
            ]
            
            print(f"æ‰§è¡ŒéŸ³é¢‘ç”Ÿæˆå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print(f"éŸ³é¢‘ç”ŸæˆæˆåŠŸ: {audio_filename}")
                print(f"éŸ³é¢‘ç”Ÿæˆè¾“å‡º: {result.stdout}")
            else:
                print(f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {result.stderr}")
                return new_history, "", self.current_video, f"âš ï¸ Audio generation failed: {result.stderr}"
                
        except subprocess.TimeoutExpired:
            print("éŸ³é¢‘ç”Ÿæˆè¶…æ—¶")
            return new_history, "", self.current_video, "âš ï¸ Audio generation timeout"
        except Exception as e:
            print(f"éŸ³é¢‘ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            return new_history, "", self.current_video, f"âš ï¸ Audio generation error: {str(e)}"
        
        # 3. ç”Ÿæˆè§†é¢‘
        progress(0.6, desc="ğŸ¬ Generating response video...")
        video_filename = f"video_{int(time.time())}.mp4"
        
        try:
            # ä½¿ç”¨ç»å¯¹è·¯å¾„è°ƒç”¨run_latentsync.pyç”Ÿæˆè§†é¢‘
            current_dir = os.getcwd()
            welcome_video_abs = os.path.join(current_dir, "welcome_video.mp4")
            audio_file_abs = os.path.join(current_dir, audio_filename)
            video_file_abs = os.path.join(current_dir, video_filename)
            
            cmd = [
                "python", "run_latentsync.py",
                welcome_video_abs,  # ä½¿ç”¨ç»å¯¹è·¯å¾„
                audio_file_abs,     # ä½¿ç”¨ç»å¯¹è·¯å¾„
                video_file_abs      # ä½¿ç”¨ç»å¯¹è·¯å¾„
            ]
            
            print(f"æ‰§è¡Œè§†é¢‘ç”Ÿæˆå‘½ä»¤: {' '.join(cmd)}")
            print(f"å½“å‰å·¥ä½œç›®å½•: {current_dir}")
            print(f"è¾“å…¥è§†é¢‘è·¯å¾„: {welcome_video_abs}")
            print(f"è¾“å…¥éŸ³é¢‘è·¯å¾„: {audio_file_abs}")
            print(f"è¾“å‡ºè§†é¢‘è·¯å¾„: {video_file_abs}")
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
            
            print(f"è§†é¢‘ç”Ÿæˆè¿”å›ç : {result.returncode}")
            print(f"è§†é¢‘ç”Ÿæˆæ ‡å‡†è¾“å‡º: {result.stdout}")
            print(f"è§†é¢‘ç”Ÿæˆé”™è¯¯è¾“å‡º: {result.stderr}")
            
            if result.returncode == 0:
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                if os.path.exists(video_file_abs) and os.path.getsize(video_file_abs) > 0:
                    print(f"è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_filename}")
                    # æ›´æ–°å½“å‰è§†é¢‘
                    self.current_video = video_filename
                    # æ¸…ç†éŸ³é¢‘æ–‡ä»¶ï¼ˆä¿ç•™è§†é¢‘æ–‡ä»¶ï¼‰
                    self.cleanup_file(audio_filename)
                    return new_history, "", video_filename, f"âœ… Successfully generated response video: {video_filename}"
                else:
                    print(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º: {video_file_abs}")
                    self.cleanup_file(audio_filename)
                    return new_history, "", self.current_video, "âš ï¸ Video file was not created properly"
            else:
                print(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {result.stderr}")
                # å¦‚æœè§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œæ¸…ç†éŸ³é¢‘æ–‡ä»¶ï¼Œä½†ä¸æ›´æ–°è§†é¢‘
                self.cleanup_file(audio_filename)
                return new_history, "", self.current_video, f"âš ï¸ Video generation failed: {result.stderr}"
                
        except subprocess.TimeoutExpired:
            print("è§†é¢‘ç”Ÿæˆè¶…æ—¶")
            self.cleanup_file(audio_filename)
            return new_history, "", self.current_video, "âš ï¸ Video generation timeout"
        except Exception as e:
            print(f"è§†é¢‘ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            self.cleanup_file(audio_filename)
            return new_history, "", self.current_video, f"âš ï¸ Video generation error: {str(e)}"
    
    def cleanup_file(self, filename):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(filename):
                os.remove(filename)
                print(f"å·²æ¸…ç†æ–‡ä»¶: {filename}")
        except Exception as e:
            print(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {filename}: {str(e)}")
    
    def clear_chat(self):
        """æ¸…ç©ºèŠå¤©å†å²"""
        self.chat_session.clear_history()
        # é‡ç½®ä¸ºåˆå§‹è§†é¢‘
        self.current_video = self.initial_video
        return [], "", self.current_video, "ğŸ’¬ Chat cleared! Ready for new conversation."

def create_interface():
    app = VirtualChatApp()
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
    }
    .chat-container {
        height: 500px !important;
    }
    .video-container {
        height: 400px !important;
    }
    """
    
    with gr.Blocks(title="ğŸ¤– Virtual Chat AI", theme=gr.themes.Soft(), css=custom_css) as demo:
        # æ ‡é¢˜å’Œæè¿°
        gr.Markdown("""
        # ï¿½ï¿½ Virtual Chat with AI Host
        Chat with an AI virtual host! The AI will respond with both text and personalized video messages.
        """)
        
        with gr.Row():
            # å·¦ä¾§ï¼šèŠå¤©åŒºåŸŸ
            with gr.Column(scale=3):
                # èŠå¤©å†å²æ˜¾ç¤º
                chatbot = gr.Chatbot(
                    label="ğŸ’¬ Chat History",
                    height=500,
                    show_label=True,
                    show_share_button=False,
                    show_copy_button=True,
                    elem_classes=["chat-container"],
                    type="messages"  # ä½¿ç”¨messagesæ ¼å¼
                )
                
                # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
                with gr.Row():
                    msg_input = gr.Textbox(
                        placeholder="Type your message here and press Enter...",
                        label="Your Message",
                        lines=2,
                        scale=4,
                        max_lines=5
                    )
                    send_btn = gr.Button("Send ğŸ“¤", variant="primary", scale=1, size="lg")
                
                # æ§åˆ¶æŒ‰é’®
                with gr.Row():
                    clear_btn = gr.Button("Clear Chat ğŸ—‘ï¸", variant="secondary", size="sm")
                    
            # å³ä¾§ï¼šè§†é¢‘å’ŒçŠ¶æ€åŒºåŸŸ
            with gr.Column(scale=2):
                # è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
                video_output = gr.Video(
                    label="ğŸ¬ AI Response Video",
                    height=400,
                    autoplay=True,
                    show_share_button=False,
                    elem_classes=["video-container"],
                    value=app.initial_video  # è®¾ç½®åˆå§‹è§†é¢‘
                )
                
                # è§†é¢‘æ§åˆ¶æŒ‰é’®
                with gr.Row():
                    play_btn = gr.Button("â–¶ï¸ Play Video", variant="primary", size="sm")
                    pause_btn = gr.Button("â¸ï¸ Pause", variant="secondary", size="sm")
                    stop_btn = gr.Button("â¹ï¸ Stop", variant="secondary", size="sm")
                
                # çŠ¶æ€æ˜¾ç¤º
                status_text = gr.Textbox(
                    label="ğŸ“Š Status",
                    value="ğŸŸ¢ Ready to chat! Type your message and press Send.",
                    interactive=False,
                    lines=3,
                    max_lines=5
                )
                
                # ç³»ç»Ÿä¿¡æ¯
                gr.Markdown("""
                ### â„¹ï¸ System Info
                - **Model**: Gemini 2.0 Flash
                - **TTS**: ChatterboxTTS
                - **Video**: LatentSync Pipeline
                - **GPU**: Auto-managed
                """)
        
        # äº‹ä»¶å¤„ç†å‡½æ•°
        def handle_send(user_input, history):
            if not user_input.strip():
                return history, "", app.current_video, "âš ï¸ Please enter a message."
            
            # è°ƒç”¨å¤„ç†å‡½æ•°
            new_history, cleared_input, video_file, final_status = app.process_message(user_input, history)
            
            return new_history, cleared_input, video_file, final_status
        
        def handle_clear():
            new_history, cleared_input, cleared_video, status = app.clear_chat()
            return new_history, cleared_input, cleared_video, status
        
        # è§†é¢‘æ§åˆ¶å‡½æ•°
        def play_video():
            return "Playing video..."
        
        def pause_video():
            return "Video paused"
        
        def stop_video():
            return "Video stopped"
        
        # ç»‘å®šäº‹ä»¶
        send_btn.click(
            fn=handle_send,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input, video_output, status_text],
            show_progress=True
        )
        
        msg_input.submit(
            fn=handle_send,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input, video_output, status_text],
            show_progress=True
        )
        
        clear_btn.click(
            fn=handle_clear,
            outputs=[chatbot, msg_input, video_output, status_text]
        )
        
        # è§†é¢‘æ§åˆ¶æŒ‰é’®
        play_btn.click(fn=play_video, outputs=status_text)
        pause_btn.click(fn=pause_video, outputs=status_text)
        stop_btn.click(fn=stop_video, outputs=status_text)
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“‹ Usage Instructions", open=True):
            gr.Markdown("""
            ### Features:
            1. **Welcome Video** - Initial video loads automatically
            2. **Chat with AI** - Full Gemini conversation
            3. **Audio Generation** - Real TTS using ChatterboxTTS
            4. **Video Generation** - Real lipsync using LatentSync
            5. **Video Controls** - Manual play/pause/stop buttons
            6. **Progress Tracking** - Shows processing steps
            7. **Smart Video Update** - Only updates video when generation succeeds
            
            ### How it Works:
            - The welcome video loads when you open the page
            - When you send a message, AI generates a text response
            - Text is converted to speech using ChatterboxTTS
            - Video is generated using LatentSync pipeline
            - New video only replaces the old one when generation succeeds
            
            ### Processing Pipeline:
            1. **Text Generation** - Gemini AI creates response
            2. **Audio Generation** - ChatterboxTTS converts text to speech
            3. **Video Generation** - LatentSync creates lipsync video
            4. **Video Display** - New video replaces previous one (only if successful)
            
            ### Requirements:
            - **GPU**: Required for TTS and video generation
            - **LatentSync**: Must be cloned and configured
            - **Dependencies**: All required packages installed
            - **welcome_video.mp4**: Must exist in current directory
            """)
    
    return demo

if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        debug=True,
        show_error=True,
        favicon_path=None
    )
